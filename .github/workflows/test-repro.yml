name: Repro Checks
on:
  workflow_call:
    inputs:
      config-ref:
        type: string
        required: true
        description: A commit or tag on an associated config branch to use for the reproducibility run
      compared-config-ref:
        type: string
        required: false
        description: A commit or tag on an associated config branch to compare against
      environment-name:
        type: string
        required: true
        description: The name of a GitHub Deployment Environment that is inherited from the caller
      test-markers:
        type: string
        required: true
        description: A python expression of markers to pass to the reproducibility pytests
      model-config-tests-version:
        type: string
        required: true
        description: A version of the model-config-tests package
      payu-version:
        type: string
        required: true
        description: The payu module version used to create test virtual environment
      additional-artifact-content-paths:
        type: string
        required: false
        # For example, the value of 'checksum' will expand to something like
        # '/scratch/tm70/repro-ci/experiments/MODEL-configs/dev-CONFIG/checksum'
        # on the remote.
        description: |
          Newline-separated paths for inclusion in the release artifact.
          Note that all paths given have 'env.EXPERIMENT_LOCATION/' prepended.
    outputs:
      result:
        value: ${{ jobs.check-repro.outputs.result }}
        description: |
          Result of the repro check.
          Output is `pass` if `inputs.config-ref` is bit-reproducible with `inputs.compared-config-ref`, `fail` otherwise
      check-run-url:
        value: ${{ jobs.check-repro.outputs.check-run-url }}
        description: URL to the parsed test results
      artifact-name:
        value: ${{ jobs.repro.outputs.artifact-name }}
        description: Name of the artifact containing the checksums and test report for this repro run
      artifact-url:
        value: ${{ jobs.repro.outputs.artifact-url }}
        description: URL to the artifact containing the checksums and test report for this repro run
      experiment-location:
        value: ${{ jobs.repro.outputs.experiment-location }}
        description: Location of the experiment on the target environment
env:
  ARTIFACT_LOCAL_LOCATION: /opt/artifact
jobs:
  repro:
    # NOTE: A lot of these `vars` and `secrets` are not found in this repository. Instead, they are inherited
    # from the calling workflow (for example, `ACCESS-NRI/access-om2-configs`)
    name: Run Config On ${{ inputs.config-ref }}
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment-name }}
    outputs:
      artifact-name: ${{ steps.artifact.outputs.name }}
      artifact-url: ${{ steps.upload.outputs.artifact-url }}
      experiment-location: ${{ steps.run.outputs.experiment-location }}
    env:
      EXPERIMENT_LOCATION: ${{ vars.EXPERIMENTS_LOCATION }}/${{ github.event.repository.name }}/${{ inputs.config-ref }}
    steps:
      - name: Validate ${{ inputs.environment-name }} Variables
        run: |
          vars_unset=false

          if [ -z "${{ vars.EXPERIMENTS_LOCATION }}" ]; then
            echo "::error::vars.EXPERIMENTS_LOCATION is unset."
            vars_unset=true
          fi
          if [ -z "${{ vars.PRERELEASE_MODULE_LOCATION }}" ]; then
            echo "::error::vars.PRERELEASE_MODULE_LOCATION is unset."
            vars_unset=true
          fi
          if [ -z "${{ vars.MODULE_LOCATION }}" ]; then
            echo "::error::vars.MODULE_LOCATION is unset."
            vars_unset=true
          fi

          if [ "$vars_unset" == "true" ]; then
            echo "::error::Required vars in ${{ inputs.environment-name }} are unset. Repro cannot be run."
            exit 1
          fi

      - name: Setup SSH
        id: ssh
        uses: access-nri/actions/.github/actions/setup-ssh@main
        with:
          hosts: |
            ${{ secrets.SSH_HOST }}
            ${{ secrets.SSH_HOST_DATA }}
          private-key: ${{ secrets.SSH_KEY }}

      - name: Run configuration
        id: run
        env:
          BASE_EXPERIMENT_LOCATION: ${{ env.EXPERIMENT_LOCATION }}/base-experiment
          COMPARED_CHECKSUM_LOCATION: ${{ env.EXPERIMENT_LOCATION }}/compared
          TEST_VENV_LOCATION: ${{ env.EXPERIMENT_LOCATION }}/test-venv
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} -i ${{ steps.ssh.outputs.private-key-path }} /bin/bash<<'EOT'

          # Remove base experiment (and everything else) if it exists
          if [ -d "${{ env.EXPERIMENT_LOCATION }}" ]; then
            rm -rf "${{ env.EXPERIMENT_LOCATION }}"
          fi
          mkdir -p "${{ env.EXPERIMENT_LOCATION }}"

          # Setup a base experiment
          git clone ${{ github.event.repository.clone_url }} "${{ env.BASE_EXPERIMENT_LOCATION }}"
          git -C "${{ env.BASE_EXPERIMENT_LOCATION }}" checkout ${{ inputs.config-ref }}
          cd "${{ env.BASE_EXPERIMENT_LOCATION }}"

          # Setup a compared checksum (if it exists)
          if [ -n "${{ inputs.compared-config-ref }}" ]; then
            git clone ${{ github.event.repository.clone_url }} "${{ env.COMPARED_CHECKSUM_LOCATION }}"
            git -C "${{ env.COMPARED_CHECKSUM_LOCATION }}" checkout ${{ inputs.compared-config-ref }}
            COMPARED_CHECKSUM_FILE=$(find "${{ env.COMPARED_CHECKSUM_LOCATION }}" -type f -name 'historical-*hr-checksum.json')

            # Error checking...
            if [ -z "$COMPARED_CHECKSUM_FILE" ]; then
              echo '::error::Did not find a `testing/checksum/historical-*hr-checksum.json` file in ${{ inputs.compared-config-ref }}. Exiting.'
              exit 1
            elif [ $(echo "$COMPARED_CHECKSUM_FILE" | wc -w) -gt 1 ]; then
              echo '::error::Found more than one `testing/checksum/historical-*hr-checksum.json` file in ${{ inputs.compared-config-ref }}. Exiting.'
              exit 2
            fi
          fi

          # Load payu module
          if [ "${{ inputs.payu-version }}" == "dev" ]; then
            echo "::warning::Using the prerelease module payu/dev for testing"
            module use ${{ vars.PRERELEASE_MODULE_LOCATION }}
          else
            module use ${{ vars.MODULE_LOCATION }}
          fi
          module load payu/${{ inputs.payu-version }}

          # Create testing virtual environment
          # Note: --system-site-packages uses packages from payu modules
          python3 -m venv "${{ env.TEST_VENV_LOCATION }}" --system-site-packages

          # Activate environment
          source "${{ env.TEST_VENV_LOCATION }}/bin/activate"

          # Install model-config-tests
          pip install model-config-tests==${{ inputs.model-config-tests-version }}

          # The pytests in model-config-tests might fail in this command,
          # but that is okay. We still want to run the rest of the commands
          # after this step.
          set +e

          # Run model-config-tests pytests - this also generates checksums files.
          # If there is a checksum to compare against, add --checksum-path arg.
          model-config-tests -s -m "${{ inputs.test-markers }}" \
            --output-path "${{ env.EXPERIMENT_LOCATION }}" \
            ${{ inputs.compared-config-ref != '' && '--checksum-path $COMPARED_CHECKSUM_FILE \' || '\' }}
            --junitxml="${{ env.EXPERIMENT_LOCATION }}/checksum/test_report.xml"

          # Deactivate and remove the test virtual environment
          deactivate
          rm -rf "${{ env.TEST_VENV_LOCATION }}"

          # We want the exit code post-`pytest` to be 0 so the overall `ssh` call succeeeds
          # after a potential `pytest` error.
          exit 0
          EOT
          echo "experiment-location=${{ env.EXPERIMENT_LOCATION }}" >> $GITHUB_OUTPUT

      - name: Copy Back Checksums and Test Report
        run: |
          rsync --recursive --verbose -e 'ssh -i ${{ steps.ssh.outputs.private-key-path }}' \
            '${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST_DATA }}:${{ env.EXPERIMENT_LOCATION }}/checksum' \
            ${{ env.ARTIFACT_LOCAL_LOCATION }}

      - name: Copy Back Additional Artifact Content
        if: inputs.additional-artifact-content-paths != ''
        # For each of the additional artifact content paths, rsync the data
        # from the target into our runner for upload as an artifact
        run: |
          while IFS= read -r content_path; do
            if [[ -n "$content_path" ]]; then
              rsync --recursive --relative --verbose -e 'ssh -i ${{ steps.ssh.outputs.private-key-path }}' \
                "${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST_DATA }}:${{ env.EXPERIMENT_LOCATION }}/./$content_path" \
                ${{ env.ARTIFACT_LOCAL_LOCATION }}
            fi
          done <<< "${{ inputs.additional-artifact-content-paths }}"

      - name: Generate Test Output Artifact Name
        id: artifact
        run: echo "name=${{ github.event.repository.name }}-${{ inputs.config-ref }}" >> $GITHUB_OUTPUT

      - name: Upload Test Output
        id: upload
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.artifact.outputs.name }}
          if-no-files-found: error
          path: ${{ env.ARTIFACT_LOCAL_LOCATION }}

  check-repro:
    # Parse the test report and return pass/fail result
    name: Check Repro Result
    needs:
      - repro
    runs-on: ubuntu-latest
    permissions:
      checks: write
    env:
      TESTING_LOCAL_LOCATION: /opt/testing
    outputs:
      # URL for the parsed test results
      check-run-url: ${{ steps.results.outputs.check-url }}
      # Overall result of the checksum repro CI - `pass` (if reproducible), `fail` otherwise
      result: ${{ steps.results.outputs.result }}
    steps:
      - name: Download Newly Created Checksum
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.repro.outputs.artifact-name }}
          path: ${{ env.TESTING_LOCAL_LOCATION }}

      - name: Parse Test Report
        id: tests
        uses: EnricoMi/publish-unit-test-result-action/composite@82082dac68ad6a19d980f8ce817e108b9f496c2a  #v2.17.1
        with:
          files: ${{ env.TESTING_LOCAL_LOCATION }}/checksum/test_report.xml
          comment_mode: off
          check_run: true
          check_name: Repro Test Results
          compare_to_earlier_commit: false
          report_individual_runs: true
          report_suite_logs: any

      - name: Checksum Tests Results
        id: results
        run: |
          echo "check-url=${{ fromJson(steps.tests.outputs.json).check_url }}" >> $GITHUB_OUTPUT

          if (( ${{ fromJson(steps.tests.outputs.json).stats.tests_fail }} > 0 )); then
            echo "result=fail" >> $GITHUB_OUTPUT
          else
            echo "result=pass" >> $GITHUB_OUTPUT
          fi